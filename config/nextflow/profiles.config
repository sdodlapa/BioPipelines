/*
 * BioPipelines - SLURM Profile Configuration
 * ==========================================
 * 
 * This profile properly configures Nextflow to run with SLURM
 * when executed from within a Singularity container.
 * 
 * Usage:
 *   nextflow run main.nf -profile slurm,singularity
 */

profiles {
    // Standard SLURM profile
    slurm {
        process.executor = 'slurm'
        process.queue = 'cpuspot'
        executor.queueSize = 50
        executor.submitRateLimit = '10 sec'
        executor.exitReadTimeout = '10 min'
        
        // Process defaults
        process {
            cpus = 4
            memory = '8 GB'
            time = '4h'
            
            // Error handling
            errorStrategy = 'retry'
            maxRetries = 2
            maxErrors = '-1'
            
            // Resource scaling by label
            withLabel: 'low' {
                cpus = 2
                memory = '4 GB'
                time = '2h'
            }
            withLabel: 'medium' {
                cpus = 8
                memory = '32 GB'
                time = '8h'
            }
            withLabel: 'high' {
                cpus = 16
                memory = '64 GB'
                time = '24h'
            }
            withLabel: 'memory_high' {
                cpus = 8
                memory = '128 GB'
            }
        }
    }
    
    // Local execution (single node, for testing)
    local {
        process.executor = 'local'
        executor.cpus = 16
        executor.memory = '64 GB'
    }
    
    // Singularity container support
    singularity {
        singularity.enabled = true
        singularity.autoMounts = true
        singularity.cacheDir = '/scratch/sdodl001/BioPipelines/containers/cache'
        
        // Bind mounts for HPC environment
        singularity.runOptions = '''
            --bind /scratch:/scratch
            --bind /home:/home
            --bind /data:/data
        '''
    }
    
    // Docker support (for local testing)
    docker {
        docker.enabled = true
        docker.runOptions = '-v /scratch:/scratch'
    }
    
    // Test profile (small resources)
    test {
        params.max_cpus = 2
        params.max_memory = '6.GB'
        params.max_time = '2.h'
    }
    
    // ODU HPC specific settings
    odu_hpc {
        process.executor = 'slurm'
        process.queue = 'cpuspot'
        
        singularity.enabled = true
        singularity.autoMounts = true
        singularity.cacheDir = '/scratch/sdodl001/BioPipelines/containers/cache'
        singularity.runOptions = '''
            --bind /scratch:/scratch
            --bind /home:/home
        '''
        
        // Work directory
        workDir = '/scratch/sdodl001/BioPipelines/work'
        
        // Output configuration
        params.outdir = '/scratch/sdodl001/BioPipelines/data/results'
    }
}

// Global configuration
params {
    // Defaults
    max_cpus = 16
    max_memory = '64.GB'
    max_time = '24.h'
    
    // Output
    outdir = 'results'
    tracedir = "${params.outdir}/pipeline_info"
    
    // Containers base path
    containers_dir = "${projectDir}/containers/images"
}

// Manifest
manifest {
    name = 'BioPipelines'
    author = 'BioPipelines Team'
    homePage = 'https://github.com/sdodlapa/BioPipelines'
    description = 'Modular bioinformatics pipelines using containerized tools'
    mainScript = 'main.nf'
    nextflowVersion = '>=23.04.0'
    version = '1.0.0'
}

// Pipeline info reports
timeline {
    enabled = true
    file = "${params.tracedir}/timeline.html"
    overwrite = true
}

report {
    enabled = true
    file = "${params.tracedir}/report.html"
    overwrite = true
}

trace {
    enabled = true
    file = "${params.tracedir}/trace.txt"
    overwrite = true
}

dag {
    enabled = false  // Enable if graphviz is available
}

// Capture exit codes from upstream processes
process.shell = ['/bin/bash', '-euo', 'pipefail']

// Function to check max allowed resources
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR: Could not parse memory value: ${obj}"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR: Could not parse time value: ${obj}"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR: Could not parse cpus value: ${obj}"
            return obj
        }
    }
}
